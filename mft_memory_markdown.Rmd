---
title: "MFT Memory"
output:
  html_document:
    df_print: paged
editor_options: 
  chunk_output_type: console
---

This is a project testing memory for vignettes of moral transgressions. 

# Design

Participants (n = 30) incidentally encoded 120 vignettes, 15 from each of the different foundations articulated by Moral Foundations Theory (cite), by reading and vividly imagining the vignette for 6 seconds and then making a moral judgement (not morally wrong-extremely morally wrong; 1-4). 

During recognition, participants were cued with each vignette presented during study + 7-8 lures per foundation. Each vignette had up to 4 words removed, and participants were asked to select which word or words completed the vignette as they studied it as well as their confidence in their response (not confident-extremely confident; 1-4). 

Encoding took place in the scanner but retrieval did not. After retrieval, participants completed a number of surveys: moral foundations questionnaire (MFQ), 

```{r load packages, message=FALSE, warning=FALSE, include=FALSE}
library(knitr)
library(ggplot2)
library(psych)
library(lme4)
library(lmerTest)
library(ggpubr)
library(tidyr)
library(ggeffects)
library(emmeans)
library(tidyselect)
library(dplyr)
library(ordinal)
library(mixor)
library(vcrpart)
library(brms)
library(pracma)
library(forcats)
library(sjPlot)
library(RColorBrewer)
library(nortest)
library(devtools)
library(paletti)
library(showtext)
se <- function(x) sqrt(var(x)/length(x))
`%notin%` <- Negate(`%in%`)
emm_options(lmerTest.limit = 5000)
emm_options(pbkrtest.limit = 4000)
```

# Load in data
```{r Load in data, include=FALSE}
# load encoding data
encodingfiles = list.files('data/encoding', full.names = TRUE, pattern = '.csv', recursive = FALSE)
encodingFull = do.call(rbind, lapply(encodingfiles, function(x){read.csv(x, header = TRUE, stringsAsFactors = FALSE)}))
earlyencodingfiles = list.files('data/encoding/old', full.names = TRUE, pattern = '.csv', recursive = FALSE)
encodingEarly = do.call(rbind, lapply(earlyencodingfiles, function(x){read.csv(x, header = TRUE, stringsAsFactors = FALSE)}))

# load retrieval data
retfiles = list.files('data/retrieval', full.names = TRUE, pattern = '.csv', recursive = FALSE)
retFull = do.call(rbind, lapply(retfiles, function(x){read.csv(x, header = TRUE, stringsAsFactors = FALSE)}))

# load vignette key
key <- read.csv('data/key.csv', stringsAsFactors = FALSE)

# load qualtrics
# foundation_matching <- read.csv('data/qualtrics/foundation_matching_all.csv', stringsAsFactors = FALSE)
# emorate <- read.csv('data/qualtrics/emorate.csv', stringsAsFactors = FALSE)
# all_surveys <- read.csv('data/qualtrics/all_surveys.csv', stringsAsFactors = FALSE)
```

# Tidy & make encoding/retrieval dataframes
```{r Tidy encoding & retrieval dataframes, include=FALSE}

# tidy encoding
envars <- names(encodingFull) %in% c('run','pres_order','vignum','trialstart_raw','trialstart_zeroed','trialstart_TR','trialdur','intended_jitter','ITI_start_raw','ITI_start_zeroed','ITI_start_TR','ITI_duration','ITI_accuracy', 'foundation', 'vigtext') 
encoding_behav_all <- encodingFull[!envars]
encoding_behav_all <- filter(encoding_behav_all, vigfile != 99999)
encodingEarly <- filter(encodingEarly, vigfile != ' vignette')
#get rid of '.jpg' suffix
encoding_behav_all <- as.data.frame(sapply(encoding_behav_all, function(x) gsub(".jpg", "", x)), stringsAsFactors = FALSE) 
encodingEarly <-as.data.frame(sapply(encodingEarly, function(x) gsub(".JPG", "", x)), stringsAsFactors = FALSE)
encodingEarly <- select(encodingEarly, -trialstart)
#homogenize column names
names(encoding_behav_all)[4]<-"encoding_RT"
names(encodingEarly)[4]<-"encoding_RT"
#get rid of symbols, quotation marks, & any white space
encodingEarly$moral_decision <- sapply(encodingEarly$moral_decision, function(s) as.numeric(substr(s, 1, 2))) #gets rid of symbols
encoding_behav_all$moral_decision <- as.numeric(encoding_behav_all$moral_decision)
encodingEarly <- as.data.frame(sapply(encodingEarly, function(x) gsub("^\t* *\"* *| *\"* *\t*$", "", x)), stringsAsFactors = FALSE) 
encoding_behav_all <- as.data.frame(sapply(encoding_behav_all, function(x) gsub("^\t* *\"* *| *\"* *\t*$", "", x)), stringsAsFactors = FALSE) 
encoding_behav_all <- full_join(encoding_behav_all, encodingEarly, by = c('subID', 'vigfile', 'moral_decision', 'encoding_RT'))
## leaves us with 3 different encoding files: encodingFull (all data from participants from whom I have scanner info), encodingEarly (data from first 3 participants),
## encoding_behav_all (behavioral data from all participants)

# tidy key
key <- as.data.frame(sapply(key, function(x) gsub("^\t* *\"* *| *\"* *\t*$", "", x)), stringsAsFactors = FALSE)
key <- subset(key, select = -c(correct_answer, choice1, choice2, choice3)) #delete extra columns

# tidy retrieval
ret_all <- retFull
ret_all$resp <- sapply(ret_all$resp, function(s) as.numeric(substr(s, 1, 2))) #get rid of symbols
ret_all$confresp <- sapply(ret_all$confresp, function(s) as.numeric(substr(s, 1, 2))) #get rid of symbols
ret_all <- as.data.frame(sapply(ret_all, function(x) gsub("^\t* *\"* *| *\"* *\t*$", "", x)), stringsAsFactors = FALSE) #get rid of quotation marks & any white space
ret_all <- left_join(ret_all, key) #make column with category for each cue
ret_all$old <- as.numeric(substr(ret_all$category, 1,4) != 'Lure') #add old/new status of each item
ret_all$category <- sapply(ret_all$category, function(x) gsub("Lure-", "", x)) #get rid of 'Lure-' prefix
ret_all$vigfile[ret_all$vigfile == ''] = NA
names(ret_all)[8]<-"retrieval_RT"

# determine which subjects I have all data for
sort(as.numeric(levels(as.factor(encoding_behav_all$subID))))
sort(as.numeric(levels(as.factor(ret_all$subID)))) 
## missing encoding data for sub 35
## missing retrieval data for sub 36

# one big happy dataframe
encoding_behav <- subset(encoding_behav_all, encoding_behav_all$subID %in% ret_all$subID) # subset of encoding files that have corresponding retrieval files
ret <- subset(ret_all, ret_all$subID %in% encoding_behav$subID) # subset of retrieval files that have corresponding encoding files
data <- merge(ret, encoding_behav, by=c('subID', 'vigfile'), all.x = TRUE) # congolomerate of these 
#sort(as.numeric(levels(as.factor(encoding_behav$subID))))
#sort(as.numeric(levels(as.factor(data$subID))))
#sort(as.numeric(levels(as.factor(all_surveys$subID))))
dataN = length(levels(as.factor(data$subID)))
dataSubs = sort(as.numeric(levels(as.factor(data$subID))))
#qualtricsSubs = sort(as.numeric(levels(as.factor(all_surveys$subID))))

# homogenize variable names
data$category[data$category == "SN"] <- "Social-Norms"
data$category[data$category == "Lib"] <- "Liberty"
data$category[data$category == "Loy"] <- "Loyalty"
data$category[data$category == "Pure"] <- "Purity"
data$category[data$category == "Auth"] <- "Authority"
data$category[data$category == "Fair"] <- "Fairness"
data$category[data$category == "Social-Norms"] <- "Social Norms"

# make text-based response column; new responses = NA
data$text_response = ''
i = 0
for (n in data$resp) {
  i = i + 1
  if (is.na(n) == TRUE) {                       
    data$text_response[i] = NA
  }
  else if (n == 1) {
    data$text_response[i] = data$choice1[i]
  }
  else if (n == 2) {
    data$text_response[i] = data$choice2[i]
  }
  else if (n == 3) {
    data$text_response[i] = data$choice3[i]
  }
  else {
    data$text_response[i] = NA
  }
} 

# make column for superordinate category
superordinateCategory <- function(c) {
  return(ifelse(c == 'Care-Emo', 'Individualizing',
         ifelse(c == 'Care-Phys', 'Individualizing',
         ifelse(c == 'Fairness', 'Individualizing',
         ifelse(c == 'Loyalty', 'Binding',
         ifelse(c == 'Authority', 'Binding',
         ifelse(c == 'Purity', 'Binding', as.character(c))))))))
}

data$superordinate = (superordinateCategory(data$category))

# make column for modeling proportion correct
data$correct <- as.numeric((!is.na(data$text_response) & data$text_response == data$correct_answer) |
  (is.na(data$text_response) & data$old == 0))

# convert RTs & moral judgment to numeric
RT_cols <- c(9,11,15)
data[, RT_cols] <- data %>% select(ends_with('RT')) %>% sapply(as.numeric)
data <- data %>% filter(retrieval_RT > 0.25) %>%
  filter(confRT > 0.25) %>%
  mutate(moral_decision=as.numeric(moral_decision),
         confresp=as.numeric(confresp),
         category=factor(category, levels=c('Social Norms', 
                                               'Authority', 'Loyalty', 'Purity', 
                                                'Liberty', 
                                               'Care-Emo', 'Care-Phys', 'Fairness')),
         old=factor(old, levels = c('1', '0')))

data_old <- subset(data, old == '1', retrieval_RT > 0.25)
```

# prep for making fancy plots
```{r}
# make custom color palette
## shoutout https://edwinth.github.io/blog/paletti/ for the elegant paletti method of doing this
## https://learnui.design/tools/data-color-picker.html used for generating the gradients, but I heavily tweaked the default output
colors <- c('#c179f7', '#f59692', '#e65e60', '#cc2943','#7CAE00', '#bfd2f2', '#86b1e4', '#2b8cd6')
viz_palette(colors)
MFT_fill  <- get_scale_fill(get_pal(colors))
MFT_color <- get_scale_color(get_pal(colors))

# import font I'm using on my poster
font_add_google('Lato', 'Lato')
font_add_google('Roboto', 'Roboto')
showtext_auto()
quartz()
```

# Analyses: Linear Mixed Models
## Moral Judgments
```{r, fig.width=5, fig.height=5}

# look at spread of moral judgement
ggplot(data_old, aes(x=moral_decision, color=category, fill=category)) +
  geom_bar() + 
  facet_wrap(~category, nrow=2) + 
  ggtitle('Distribution of Moral Judgments') +
  xlab('1=not morally wrong, 4=extremely morally wrong')

# make plot comparing to moral responses observed in Clifford et al
category_means <- data_old %>% 
  mutate(category=factor(category, levels = c('Care-Emo', 'Care-Phys', 'Fairness', 
                                              'Loyalty', 'Authority', 'Purity', 'Liberty', 'Social Norms'))) %>% 
  group_by(category, subID) %>% summarise(mean = mean(as.integer(moral_decision))) 
ggplot(category_means, aes(x=category, y=mean, color=category, fill=category)) +
  stat_summary(fun.y = mean, geom='bar') +
  stat_summary(fun.data=mean_se, fun.args = list(mult=1.96), geom='errorbar', color='black', size=0.5, width=0.5) +
  coord_flip() +
  ggtitle('Visual comparison to Clifford et al. (2015)')


# linear mixed effect model
modelMoral <- lmer(moral_decision ~ category + (1 | subID) + (1|vigfile), data = data_old, control=lmerControl(optCtrl = list(maxeval=5000))) 
summary(modelMoral)
##sjt.lmer(modelMoral)

# plot estimated marginal means
modelMoral_df <- as.data.frame(emmeans(modelMoral, ~ category))

ggplot(modelMoral_df, aes(x=category, y=emmean)) +
  ylim(1,4) +
  labs(x = 'Foundation', y='Estimated marginal mean', fill='Foundation') +
  geom_violin(data=data_old, mapping=aes(y=moral_decision, fill=category), alpha=0.85, bw=0.4) + 
  geom_pointrange(aes(ymin=lower.CL, ymax=upper.CL), alpha=1, fatten=5, color='black') +
  MFT_fill() + MFT_color() +
  theme_pubr(legend = 'none', base_family = 'Lato') +
  theme(axis.title.x = element_text(size = 14),
        axis.title.y = element_text(size=14),
        title = element_text(size=16)) +
  ggtitle('Moral judgments')

ggsave('figures/moral_judgments.png', dpi=1200)

superordinateContrasts <- list(LibertyVsSocial=c(-1, 1, 0, 0, 0, 0, 0, 0),
                BindingVsSocial=c(-1, 0, 1/3, 1/3, 1/3, 0, 0, 0),
                IndividualizingVsSocial=c(-1, 0, 0, 0, 0, 1/3, 1/3, 1/3),
                LibertyVsBinding=c(0, -1, 1/3, 1/3, 1/3, 0, 0, 0),
                LibertyVsIndividualizing=c(0, -1, 0, 0, 0, 1/3, 1/3, 1/3),
                BindingVsIndividualizing=c(0, 0, -1/3, -1/3, -1/3, 1/3, 1/3, 1/3))

# superordinate contrasts
moralContrasts <- emmeans(modelMoral, ~ category) %>% contrast(superordinateContrasts, adjust='bonferroni')

```

### PLS results
```{r}

mean_brain_scores <- read.csv('data/mean_brain_scores.csv')
mean_brain_scores$category <- matlab_categories
mean_brain_scores$superordinate <- superordinateCategory(mean_brain_scores$category)
upper_CIs <- read.csv('data/upper_CIs.csv')
lower_CIs <- read.csv('data/lower_CIs.csv')
colnames(upper_CIs) <- paste0('upper_', colnames(upper_CIs))
colnames(lower_CIs) <- paste0('lower_', colnames(lower_CIs))
mean_centered_results_LV1 <- select(mean_brain_scores, category, superordinate, LV1)
mean_centered_results_LV1$upper <- upper_CIs$upper_LV1
mean_centered_results_LV1$lower <- lower_CIs$lower_LV1
mean_centered_results_LV1$category <- factor(mean_centered_results_LV1$category, 
                                             levels=c('Social Norms',
                                               'Authority', 'Loyalty', 'Purity', 'Liberty', 
                                               'Care-Emo', 'Care-Phys', 'Fairness'))

ggplot(data = mean_centered_results_LV1, 
       aes(x=category, y=LV1, fill=category, color=category)) +
  geom_hline(aes(yintercept = 0), size = 0.5) +
  ylab('Brain scores') + xlab('Foundation') +
  geom_col(color='black') + 
  geom_point(color='black', size=1) +
  geom_errorbar(aes(ymax = upper, ymin = lower), color='black', size=0.5, width=0.25) +
  MFT_fill() + MFT_color() +
  theme_pubr(legend = 'none', base_family = 'Lato') +
  theme(axis.title.x = element_text(size = 14),
        axis.title.y = element_text(size=14),
        title = element_text(size=16)) +
  ggtitle('LV1: 25.81% crossblock variance, p < 0.004')

ggsave('figures/LV1.png', dpi = 1200)

mean_centered_results_LV2 <- select(mean_brain_scores, category, superordinate, LV2)
mean_centered_results_LV2$upper <- upper_CIs$upper_LV2
mean_centered_results_LV2$lower <- lower_CIs$lower_LV2
mean_centered_results_LV2$category <- factor(mean_centered_results_LV2$category, 
                                             levels=c('Social Norms', 
                                               'Authority', 'Loyalty', 'Purity', 'Liberty', 
                                               'Care-Emo', 'Care-Phys', 'Fairness'))

ggplot(data = mean_centered_results_LV2, 
       aes(x=category, y=LV2, color=category, fill=category)) +
  geom_hline(aes(yintercept = 0), size = 0.5) +
  ylab('Brain scores') + xlab('Foundation') +
  geom_col(color='black') + 
  geom_point(color='black', size=1) +
  geom_errorbar(aes(ymax = upper, ymin = lower), color='black', size=0.5, width=0.25) +
  MFT_fill() + MFT_color() +
  theme_pubr(legend = 'none', base_family = 'Lato') +
  theme(axis.title.x = element_text(size = 14),
        axis.title.y = element_text(size=14),
        title = element_text(size=16)) +
  ggtitle('LV2: 18.21% crossblock variance, p < 0.042')

ggsave('figures/LV2.png', dpi = 1200)

```

### Temporal Brain Scores
```{r, fig.width=5, fig.height=5}
LV1 <- read.csv('data/brainscores_LV1.csv')
LV2 <- read.csv('data/brainscores_LV2.csv')
LV1$subID <- rep(dataSubs, each = 8)
LV2$subID <- rep(dataSubs, each = 8)
matlab_categories <- c('Authority', 'Care-Emo', 'Care-Phys', 'Fairness', 'Liberty', 
                       'Loyalty', 'Purity', 'Social Norms')
LV1$category <- matlab_categories
LV2$category <- matlab_categories

LV1 <- pivot_longer(LV1, cols = starts_with('Lag'), names_to = 'lag', values_to = 'score')
LV2 <- pivot_longer(LV2, cols = starts_with('Lag'), names_to = 'lag', values_to = 'score')

modelLV1 <- lmer(score ~ lag * category + (1 | subID), data = LV1)
summary(modelLV1)

modelLV1 %>% emmeans(~ lag * category) %>% as.data.frame() %>%
  mutate(superordinate = superordinateCategory(category),
         category = factor(category, levels = c('Social Norms', 'Authority', 'Loyalty', 'Purity',
                             'Liberty', 'Care-Emo', 'Care-Phys', 'Fairness'))) %>%
  ggplot(aes(x=lag, y=emmean, group=category, color=category, fill=category))  + 
  scale_x_discrete(expand = c(0, 0, 0, 0.05)) +
  geom_hline(aes(yintercept = 0), size=1) +
  geom_line(size=1) + 
  geom_point(aes(fill=category, color=category, shape = category), size=3) +
  scale_shape_manual(values = c(4,15,16,17,3,0,1,2)) +
  MFT_fill() + MFT_color() +
  theme_pubr(legend = 'right', base_family = 'Lato') +
  theme(axis.title.x = element_text(size = 14),
        axis.title.y = element_text(size=14),
        title = element_text(size=16)) +
  labs(y = 'Brain score', x= 'TR=2s', color='Foundation', fill='Foundation', shape='Foundation')
  ggtitle('Temporal brain scores: LV1')

ggsave('figures/brainscores_LV1.png', dpi = 1200, width = 10, height = 10)

modelLV2 <- lmer(score ~ lag * category + (1 | subID), data = LV2)
summary(modelLV2)

modelLV2 %>% emmeans(~ lag * category) %>% as.data.frame() %>% 
  mutate(superordinate = superordinateCategory(category),
         category = factor(category, levels = c('Social Norms', 'Authority', 'Loyalty', 'Purity',
                             'Liberty', 'Care-Emo', 'Care-Phys', 'Fairness'))) %>%
  ggplot(aes(x=lag, y=emmean, group=category, color=category, fill=category)) + 
  scale_x_discrete(expand = c(0, 0, 0, 0.05)) +
  geom_hline(aes(yintercept = 0), size=1) +
  geom_line(size=1) + 
  geom_point(aes(color=category, shape = category), size=3) +
  scale_shape_manual(values = c(4,15,16,17,3,0,1,2)) +
  MFT_fill() + MFT_color() +
  theme_pubr(legend = 'right', base_family = 'Lato') +
  theme(axis.title.x = element_text(size = 14),
        axis.title.y = element_text(size=14),
        title = element_text(size=16)) +
  labs(y = 'Brain score', x= 'TR=2s', color='Foundation', fill='Foundation', shape='Foundation') +
  ggtitle('Temporal brain scores: LV2')

ggsave('figures/brainscores_LV2.png', dpi = 300, width = 10, height = 10)
```

## Memory
### Accuracy (hits & correct rejections)
```{r, fig.width=20, fig.height=8}

# generalized linear mixed effect model (outcome is binary)
modelMemory <- glmer(correct ~ category * old + (1 | subID),
                 data=data, family=binomial(link = 'logit'), control=glmerControl(optCtrl=list(maxfun=50000)))
summary(modelMemory)

# plotting prep
data <- data %>% group_by(subID, category, old) %>% mutate(propCorrect = mean(correct)) # so that violin plots can reflect participant response densities
memLabels <- c('0' = "New", '1' = 'Old') # labels for faceting 

# plot
modelMemory %>% emmeans(~ category * old, type='response') %>% as.data.frame %>%
  ggplot(aes(x=category, y=prob)) +
  facet_grid(.~old, labeller = labeller(old=memLabels)) +
  geom_violin(aes(x=category, y=propCorrect, color=superordinate, fill=superordinate), data=data, alpha=0.7, scale='count', bw=.1) +
  geom_pointrange(aes(ymax=asymp.LCL, ymin=asymp.UCL), alpha=1, fatten=1, color='black') +
  theme(strip.text.x = element_text(size=10, face='bold')) +
  ylab('Estimated probability of correct response') +
  ggtitle('Memory accuracy (hits & correct rejections)') 

ggsave('memory_accuracy.png', dpi = 600)

# superordinate contrasts
emmeans(modelMemory, ~ category) %>%
  contrast(superordinateContrasts, adjust='bonferroni')

```

### Reaction Time
```{r}

data_old$category <- factor(data_old$category, levels = c('Social Norms', 'Authority', 'Loyalty', 'Purity', 
                                    'Care-Emo', 'Care-Phys', 'Fairness', 'Liberty'))

data <- data %>%
  filter(retrieval_RT > 0.02) %>%
  mutate(log_retrieval_RT=log(retrieval_RT))
hist(data$log_retrieval_RT, breaks = 100)
ks.test(data$log_retrieval_RT)

# analyze
modelRetRT <- lmer(log_retrieval_RT ~ category * correct * old + (1 | subID) + (1 | vigfile), data=data)
summary(modelRetRT)

# plot
modelRetRT %>% emmeans(~ category * correct * old) %>% as.data.frame() %>% 
  ggplot(aes(x=category, y=exp(emmean))) +
  facet_grid(. ~ old, labeller = (old=as_labeller(memLabels))) +
  geom_pointrange(aes(ymax=exp(asymp.LCL), ymin=exp(asymp.UCL), color=correct), alpha=1, fatten=5, position=position_dodge(0.5))+
  scale_color_manual(values = c("deepskyblue4", "goldenrod1")) +
  theme(strip.text.x = element_text(size=10, face='bold'), strip.text.y = element_text(size=10, face='bold')) +
  ylab('Reaction time (seconds)') +
  ggtitle('Retrieval reaction time') 

```

### Confidence
```{r, fig.width=8, fig.height=4}

data$correct <- as.factor(data$correct)
confLabels <- c('1' = 'Correct', '0' = 'Incorrect')
data <- data %>% group_by(subID, category, old, correct) %>% mutate(averageConf = mean(confresp))
data$category <- factor(data$category, levels = c('Social Norms', 'Authority', 'Loyalty', 'Purity', 
                                    'Care-Emo', 'Care-Phys', 'Fairness', 'Liberty'))

# explore spread
ggplot(data, aes(x=confresp, fill=category)) +
  geom_bar() + 
  facet_grid(old~category, labeller = labeller(old=memLabels)) + 
  ggtitle('Distribution of Confidence judgments in each category') +
  xlab('1=not confident at all, 4=extremely confident')

ggplot(data, aes(x=confresp, color=category, fill=category)) +
  geom_bar() + 
  facet_grid(correct~category, labeller = labeller(correct=confLabels)) + 
  ggtitle('Distribution of Confidence Judgments by Accuracy') +
  xlab('1=not confident at all, 4=extremely confident')

# run model
modelConfidence <- lmer(confresp ~ category + old * correct + (1 + category | subID), data=data,
                        control=lmerControl(optCtrl = list(maxeval=5000)))
summary(modelConfidence)

# plot
modelConfidence %>% emmeans(~ category * old * correct, type='response') %>% as.data.frame %>%
  ggplot(aes(x=category, y=emmean)) +
  facet_wrap(. ~ old, labeller = (old=as_labeller(memLabels))) +
  geom_violin(aes(x=category, y=averageConf, fill=superordinate, group=interaction(category,correct)), data=data, alpha=0.7, scale='count', bw=0.4, position = position_dodge(1)) +
  geom_pointrange(aes(ymax=asymp.LCL, ymin=asymp.UCL, color=correct), alpha=1, fatten=3, position=position_dodge(1)) + 
  scale_color_manual(values = c('white', "black"), labels = c('incorrect', 'correct')) +
  theme(strip.text.x = element_text(size=10, face='bold'), strip.text.y = element_text(size=10, face='bold')) +
  ylab('Estimated mean confidence') +
  ggtitle('Memory confidence') 

ggsave('memory_confidence.png', dpi = 600)

emmeans(modelConfidence, ~ category) %>%
  contrast(superordinateContrasts, adjust='bonferroni')

```

### Confidence reaction Time
```{r}

# visualize spread
hist(data$confRT)
data <- data %>% 
  filter(confRT > 0.01) %>%
  mutate(log_conf_RT=log(confRT))




```
### Encoding reaction time
```{r}

# visualize
hist(data_old$encoding_RT, breaks = 100)
# test for normality
shapiro.test(data_old$encoding_RT) # failed :(
# log transform
data_old <- data_old %>% mutate(log_moral_RT = log(encoding_RT))
hist(data_old$log_moral_RT, breaks = 100)
shapiro.test(data_old$log_moral_RT)

modelMoralRT <- lmer(encoding_RT ~ category + (1 | subID) + (1 | vigfile), data=data_old)
summary(modelMoralRT)

# plot
modelMoralRT %>% emmeans(~ category) %>% as.data.frame() %>% 
  ggplot(aes(x=category, y=emmean)) +
  geom_violin(data=data_old, mapping=aes(y=encoding_RT, fill = superordinate, color=superordinate), alpha=0.7) +
  geom_pointrange(aes(ymax=upper.CL, ymin=lower.CL), alpha=1, fatten=3, color = 'black', size=1) +
  ylab('Reaction time (seconds)') +
  ggtitle('Moral judgment reaction time (model estimates + raw data)') 

modelMoralRT %>% emmeans(~ category) %>% as.data.frame() %>% 
  ggplot(aes(x=category, y=emmean)) +
  geom_pointrange(aes(ymax=upper.CL, ymin=lower.CL, color=category), alpha=1, fatten=8) +
  ylab('Reaction time (seconds)') +
  ggtitle('Moral judgment reaction time (model estimates only)') 

```

``` {r}
## some handy commands
# exp(fixef(modelOld1)): transforms model output from log likelihood to odds ratio
# anova(modelOld1, modelOld2): use for model comparisons [**don't look at the output of either model; use the results of this comparison to guide your result-seeking**]
# emmeans(modelNew, pairwise ~ category): gives you marginal means for each level of the fixed effect factor & pairwise comparisons among levels of the factor
# emmeans(modelNew, 'category', type='response'): gives you probabilities for each level of the fixed effect factor
# emmeans(modelOld1, pairwise ~ category, lmer.df = "satterthwaite"): gives you probabilities for each fixed effect and odds ratios + p-values for pairwise comparisons among levels of the fixed effect factor

# ggplot(category_means, aes(x=category, y=mean, color=category, fill=category)) +
#   geom_violin(scale='count', alpha=0.5) +
#   stat_summary(fun.data = mean_se, fun.args = list(mult = 1.96), geom='pointrange', color='black', fatten=5) +
#   ggtitle('Mean moral judgment per category')

# test for meeting assumption of proportional odds
# data_old$category <-  factor(data_old$category, levels = c('Social Norms', 'Care-Emo', 'Care-Phys', 'Fairness', 'Loyalty', 'Authority', 'Purity', 'Liberty')) # re-level category so that Social Norms is the intercept
# modelMoral.clm <- clm(moral_decision ~ category + subID, data = data_old)
# nominal_test(modelMoral.clm)
# scale_test(modelMoral.clm) # failed both tests (highly significant, p < 2.2e-16)

# partial proportional odds using vcrpart -- didn't fit
# modelMoral.olmm <- olmm(as.factor(moral_decision) ~ ce(category) + re(1 + category | subID), data = data_old, 
#                         family = cumulative(link = 'logit'))

# partial proportional odds using mixor -- didn't fit
# modelMoral.mix <- mixor(moral_decision ~ category, data = data_old, id = subID, KG=1, link = 'logit')

# Bayesian Generalized Linear Multivariate Multilevel Model (probably not gonna use but keeping the code here just in case)
# modelMoral <- brm(moral_decision ~ category + (1 + category | subID) + (1 | vigfile), 
#                   family=cumulative(link="logit", threshold="flexible"), data=data_old, cores=4, file='mftMoralDecision')
# summary(modelMoral)
# conditional_effects(modelMoral)
# conditional_effects(modelMoral, categorical=TRUE)


# modelRetRT2 <- glmer(retrieval_RT ~ category + (1 | subID) + (1 | vigfile), data=data_old, family = Gamma(link='logit'))
# 
# modelRetRT3 <- glmer(retrieval_RT ~ category + (1 | subID) + (1 | vigfile), data=data_old, family = inverse.gaussian(link = 'logit'), start=list(rho=0.5))

```

# Tidy Questionnaires
```{r Tidy questionnaires, include=FALSE}
# mfq <- select(all_surveys, starts_with('sub'), starts_with('mfq'))
# disgust_scale <- select(all_surveys, starts_with('sub'), starts_with('disgust'))
# secs <- select(all_surveys, starts_with('sub'), starts_with('secs'))
# iri <- select(all_surveys, starts_with('sub'), starts_with('iri'))
# 
# # score MFQ
# #part one
# mfq[mfq == 'Not at all relevant' ] <- 0
# mfq[mfq == 'Not very relevant' ] <- 1
# mfq[mfq == 'Slightly relevant' ] <- 2
# mfq[mfq == 'Somewhat relevant' ] <- 3
# mfq[mfq == 'Very relevant' ] <- 4
# mfq[mfq == 'Extremely relevant' ] <- 5
# #part two
# mfq[mfq == 'Strongly disagree' ] <- 0
# mfq[mfq == 'Moderately disagree' ] <- 1
# mfq[mfq == 'Slightly disagree' ] <- 2
# mfq[mfq == 'Slightly agree' ] <- 3
# mfq[mfq == 'Moderately agree' ] <- 4
# mfq[mfq == 'Strongly agree' ] <- 5
# # compute results
# colnames(mfq) <- substr(colnames(mfq), 5, 7) 
# names(mfq)[1] <- 'subID'
# mfq <- mfq[-1,]
# mfq[,2:33] <- as.numeric(unlist(mfq[,2:33]))
# mfq <- mfq %>% mutate(careScore = rowSums(select(., c('1','7','12','17','23','28')), na.rm = TRUE),
#                      fairnessScore = rowSums(select(., c('2','8','13','18','24','29')), na.rm = TRUE),
#                      loyaltyScore = rowSums(select(., c('3','9','14','19','25','30')), na.rm = TRUE),
#                      authorityScore = rowSums(select(., c('4','10','15','20','26','31')), na.rm = TRUE),
#                      purityScore = rowSums(select(., c('5','11','16','21','27','32')), na.rm = TRUE))
# hist(mfq$careScore) #slight negative skew, peak at 20-25 (count=12)
# hist(mfq$fairnessScore) #considerable negative skew, peak at 20-25 (count=15)
# hist(mfq$loyaltyScore) #more centrally distributed, peak at 10-15 (count=11) & 15-20 (count=12)
# hist(mfq$authorityScore) #considerable negative skew, peak at 10-15 (count=12)
# hist(mfq$purityScore) #most normally distributed of them all, peak at 15-20 (count=10)
# 
# # add to retrieval file
# # mfq_ret <- subset(mfq, subID %in% ret_all$subID) %>% filter(subID != '20') %>% select(contains('Score'), contains('subID'))
# # ret_all <- left_join(ret_all, mfq_ret, by = 'subID')
# 
# 
# # score disgust_scale
# #part one
# disgust_scale[disgust_scale == 'Strongly disagree' ] <- 0
# disgust_scale[disgust_scale == 'Mildly disagree' ] <- 1
# disgust_scale[disgust_scale == 'Neither agree nor disagree' ] <- 2
# disgust_scale[disgust_scale == 'Mildly agree' ] <- 3
# disgust_scale[disgust_scale == 'Strongly agree' ] <- 4
# #part two
# disgust_scale[disgust_scale == 'Not disgusting at all' ] <- 0
# disgust_scale[disgust_scale == 'Slightly disgusting' ] <- 1
# disgust_scale[disgust_scale == 'Moderately disgusting' ] <- 2
# disgust_scale[disgust_scale == 'Very disgusting' ] <- 3
# disgust_scale[disgust_scale == 'Extremely disgusting' ] <- 4
# # compute results
# colnames(disgust_scale) <- as.character(c('subID', 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27)) 
# disgust_scores <- select(disgust_scale, -'12', -'16') #get rid of catch questions
# disgust_scores <- as.data.frame(disgust_scores[-1,]) 
# disgust_scores[,2:25] <- as.numeric(unlist(disgust_scores[,2:25]))
# reverse4 <- function(x) 4 - x
# disgust_scores[,c('1','6','10')] <- reverse4(disgust_scores[,c('1','6','10')])
# disgust_scores$score <- rowSums(disgust_scores[2:25])
# hist(disgust_scores$score) #pretty normally distributed, peak at 50-60 (count=11)
# 
# 
# # score iri
# iri <- as.data.frame(sapply(iri, function(s) substr(s, 1, 2)), stringsAsFactors = FALSE)
# colnames(iri) <- substr(colnames(iri), 5, 7) 
# iri <- as.data.frame(sapply(iri, function(x) gsub("^\t* *\"* *| *\"* *\t*$", "", x)), stringsAsFactors = FALSE)
# names(iri)[1] <- 'subID'
# iri <- iri[-1,]
# iri[iri == 'A' ] <- 0
# iri[iri == 'B' ] <- 1
# iri[iri == 'C' ] <- 2
# iri[iri == 'D' ] <- 3
# iri[iri == 'E' ] <- 4
# iri[,2:29] <- as.numeric(unlist(iri[,2:29]))
# reverseScoredIRI <- c('3', '4', '7', '12', '13', '14', '15', '18', '19')
# iri[,reverseScoredIRI] <- reverse4(iri[,reverseScoredIRI])
# #subscale coding
# perspective_taking <- c('3','8','11','15','21','25','28')
# fantasy <- c('1', '5', '7','12','16','23','26')
# empathic_concern <- c('2','4','9','14','18','20','22')
# personal_distress <- c('6','10','13','17', '19', '24','27')
# #compute scores
# iri <- iri %>% mutate(PerspectiveTakingScore = rowSums(select(., perspective_taking), na.rm = TRUE),
#                      FantasyScore = rowSums(select(., fantasy), na.rm = TRUE),
#                      EmpathicConcernScore = rowSums(select(., empathic_concern), na.rm = TRUE),
#                      PersonalDistressScore = rowSums(select(., personal_distress), na.rm = TRUE))
# 
# # explore spread
# # hist(iri$PerspectiveTakingScore)
# # hist(iri$FantasyScore)
# # hist(iri$EmpathicConcernScore)
# # hist(iri$PersonalDistressScore)
# 
# 
# # score secs - conservatism increases with score
# colnames(secs) <- substr(colnames(secs), 6, 8) 
# names(secs)[1] <- 'subID'
# secs <- secs[-1,]
# secs[,2:13] <- as.numeric(unlist(secs[,2:13]))
# social <- c('1','3','4','7','8','11','12')
# economic <- c('2', '5', '6', '9', '10')
# reverse100 <- function(x) 100 - x
# reverseScoredSECS <- c('1', '5')
# secs[,reverseScoredSECS] <- reverse100(secs[,reverseScoredSECS])
# secs <- secs %>% mutate(SocialConservatism = rowMeans(select(., social), na.rm = TRUE),
#                        EconomicConservatism = rowMeans(select(., economic), na.rm = TRUE))
# secs_ret <- subset(secs, subID %in% ret_all$subID) %>% filter(!is.nan(SocialConservatism)) %>% select(contains('subID'),contains('Conservatism'))

# explore spread
# hist(secs$SocialConservatism)
# count(secs, SocialConservatism >= 50)
# hist(secs$EconomicConservatism)
# count(secs, EconomicConservatism >= 50)

# tidy emorate
# emorate <- read.csv('C:/Users/imclab/Desktop/MFT re-analysis/data/qualtrics/emorate.csv', stringsAsFactors = FALSE)
# emorate[2:30, 2:721] <- as.data.frame(sapply(emorate[2:30, 2:721], function(s) substr(s, 1, 2)), stringsAsFactors = FALSE)
# names(emorate)[1] <- 'subID'
# emorate <- emorate[2:nrow(emorate),] %>% pivot_longer(2:ncol(emorate), names_to=c('vigfile', 'emotion'), names_pattern='([a-z]+\\d+)\\.*(.*)' , values_to='emoresp')
# emorate$emotion[emorate$emotion == ''] = 'angry'
# emorate$emotion[emorate$emotion == '1'] = 'sad'
# emorate$emotion[emorate$emotion == '2'] = 'disgusted'
# emorate$emotion[emorate$emotion == '3'] = 'afraid'
# emorate$emotion[emorate$emotion == '4'] = 'contemptuous'
# emorate$emotion[emorate$emotion == '5'] = 'amused'
# emorate$emoresp <- as.numeric(emorate$emoresp)
# emorate_ret <- subset(emorate, subID %in% ret_all$subID)
# 
# # add qualtrics information into main dataframe
# data <- left_join(data, mfq_ret, by='subID')
# data <- left_join(data, secs_ret, by='subID')
# count(data, SocialConservatism > 50)
# count(data, EconomicConservatism > 50)
# 
# data$socially_conservative[data$SocialConservatism > 50] = 1
# data$socially_conservative[data$SocialConservatism < 50] = 0
# data$fiscally_conservative[data$EconomicConservatism > 50] = 1
# data$fiscally_conservative[data$EconomicConservatism < 50] = 0

```
