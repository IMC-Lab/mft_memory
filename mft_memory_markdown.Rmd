---
title: "MFT Memory"
output:
  html_document:
    df_print: paged
editor_options: 
  chunk_output_type: console
---

This is a project testing memory for vignettes of moral transgressions. 

# Design

Participants (n = 30) incidentally encoded 120 vignettes, 15 from each of the different foundations articulated by Moral Foundations Theory (cite), by reading and vividly imagining the vignette for 6 seconds and then making a moral judgement (not morally wrong-extremely morally wrong; 1-4). 

During recognition, participants were cued with each vignette presented during study + 7-8 lures per foundation. Each vignette had up to 4 words removed, and participants were asked to select which word or words completed the vignette as they studied it as well as their confidence in their response (not confident-extremely confident; 1-4). 

Encoding took place in the scanner but retrieval did not. After retrieval, participants completed a number of surveys: moral foundations questionnaire (MFQ), 

```{r load packages, message=FALSE, warning=FALSE, include=FALSE}
library(knitr)
library(ggplot2)
library(psych)
library(lme4)
library(lmerTest)
library(ggpubr)
library(tidyr)
library(ggeffects)
library(emmeans)
library(tidyselect)
library(dplyr)
library(ordinal)
library(mixor)
library(brms)
se <- function(x) sqrt(var(x)/length(x))
`%notin%` <- Negate(`%in%`)
```

# Load in data
```{r Load in data, include=FALSE}
# load encoding data
encodingfiles = list.files('data/encoding', full.names = TRUE, pattern = '.csv', recursive = FALSE)
encodingFull = do.call(rbind, lapply(encodingfiles, function(x){read.csv(x, header = TRUE, stringsAsFactors = FALSE)}))
earlyencodingfiles = list.files('data/encoding/old', full.names = TRUE, pattern = '.csv', recursive = FALSE)
encodingEarly = do.call(rbind, lapply(earlyencodingfiles, function(x){read.csv(x, header = TRUE, stringsAsFactors = FALSE)}))

# load retrieval data
retfiles = list.files('data/retrieval', full.names = TRUE, pattern = '.csv', recursive = FALSE)
retFull = do.call(rbind, lapply(retfiles, function(x){read.csv(x, header = TRUE, stringsAsFactors = FALSE)}))

# load vignette key
key <- read.csv('data/key.csv', stringsAsFactors = FALSE)

# load qualtrics
foundation_matching <- read.csv('data/qualtrics/foundation_matching_all.csv', stringsAsFactors = FALSE)
emorate <- read.csv('data/qualtrics/emorate.csv', stringsAsFactors = FALSE)
all_surveys <- read.csv('data/qualtrics/all_surveys.csv', stringsAsFactors = FALSE)
```

# Tidy & make encoding/retrieval dataframes
```{r Tidy encoding & retrieval dataframes, include=FALSE}

# tidy encoding
envars <- names(encodingFull) %in% c('run','pres_order','vignum','trialstart_raw','trialstart_zeroed','trialstart_TR','trialdur','intended_jitter','ITI_start_raw','ITI_start_zeroed','ITI_start_TR','ITI_duration','ITI_accuracy', 'foundation', 'vigtext') 
encoding_behav_all <- encodingFull[!envars]
encoding_behav_all <- filter(encoding_behav_all, vigfile != 99999)
encodingEarly <- filter(encodingEarly, vigfile != ' vignette')
#get rid of '.jpg' suffix
encoding_behav_all <- as.data.frame(sapply(encoding_behav_all, function(x) gsub(".jpg", "", x)), stringsAsFactors = FALSE) 
encodingEarly <-as.data.frame(sapply(encodingEarly, function(x) gsub(".JPG", "", x)), stringsAsFactors = FALSE)
encodingEarly <- select(encodingEarly, -trialstart)
#homogenize column names
names(encoding_behav_all)[4]<-"encoding_RT"
names(encodingEarly)[4]<-"encoding_RT"
#get rid of symbols, quotation marks, & any white space
encodingEarly$moral_decision <- sapply(encodingEarly$moral_decision, function(s) as.numeric(substr(s, 1, 2))) #gets rid of symbols
encoding_behav_all$moral_decision <- as.numeric(encoding_behav_all$moral_decision)
encodingEarly <- as.data.frame(sapply(encodingEarly, function(x) gsub("^\t* *\"* *| *\"* *\t*$", "", x)), stringsAsFactors = FALSE) 
encoding_behav_all <- as.data.frame(sapply(encoding_behav_all, function(x) gsub("^\t* *\"* *| *\"* *\t*$", "", x)), stringsAsFactors = FALSE) 
encoding_behav_all <- full_join(encoding_behav_all, encodingEarly, by = c('subID', 'vigfile', 'moral_decision', 'encoding_RT'))
## leaves us with 3 different encoding files: encodingFull (all data from participants from whom I have scanner info), encodingEarly (data from first 3 participants),
## encoding_behav_all (behavioral data from all participants)

# tidy key
key <- as.data.frame(sapply(key, function(x) gsub("^\t* *\"* *| *\"* *\t*$", "", x)), stringsAsFactors = FALSE)
key <- subset(key, select = -c(correct_answer, choice1, choice2, choice3)) #delete extra columns

# tidy retrieval
ret_all <- retFull
ret_all$resp <- sapply(ret_all$resp, function(s) as.numeric(substr(s, 1, 2))) #get rid of symbols
ret_all$confresp <- sapply(ret_all$confresp, function(s) as.numeric(substr(s, 1, 2))) #get rid of symbols
ret_all <- as.data.frame(sapply(ret_all, function(x) gsub("^\t* *\"* *| *\"* *\t*$", "", x)), stringsAsFactors = FALSE) #get rid of quotation marks & any white space
ret_all <- left_join(ret_all, key) #make column with category for each cue
ret_all$old <- as.integer(substr(ret_all$category, 1,4) != 'Lure') #add old/new status of each item
ret_all <- as.data.frame(sapply(ret_all, function(x) gsub("Lure-", "", x)), stringsAsFactors = FALSE) #get rid of 'Lure-' prefix
ret_all$vigfile[ret_all$vigfile == ''] = NA
names(ret_all)[8]<-"retrieval_RT"

# determine which subjects I have all data for
sort(as.numeric(levels(as.factor(encoding_behav_all$subID))))
sort(as.numeric(levels(as.factor(ret_all$subID)))) 
## missing encoding data for sub 35
## missing retrieval data for sub 36

# one big happy dataframe
encoding_behav <- subset(encoding_behav_all, encoding_behav_all$subID %in% ret_all$subID) # subset of encoding files that have corresponding retrieval files
ret <- subset(ret_all, ret_all$subID %in% encoding_behav$subID) # subset of retrieval files that have corresponding encoding files
data <- merge(ret, encoding_behav, by=c('subID', 'vigfile'), all.x = TRUE) # congolomerate of these 
#sort(as.numeric(levels(as.factor(encoding_behav$subID))))
#sort(as.numeric(levels(as.factor(data$subID))))
#sort(as.numeric(levels(as.factor(all_surveys$subID))))
dataN = length(levels(as.factor(data$subID)))
dataSubs = sort(as.numeric(levels(as.factor(data$subID))))
qualtricsSubs = sort(as.numeric(levels(as.factor(all_surveys$subID))))

# homogenize variable names
data$category[data$category == "SN"] <- "Social-Norms"
data$category[data$category == "Lib"] <- "Liberty"
data$category[data$category == "Loy"] <- "Loyalty"
data$category[data$category == "Pure"] <- "Purity"
data$category[data$category == "Auth"] <- "Authority"
data$category[data$category == "Fair"] <- "Fairness"
data$category[data$category == "Social-Norms"] <- "Social Norms"

# make text-based response column; new responses = NA
data$text_response = ''
i = 0
for (n in data$resp) {
  i = i + 1
  if (is.na(n) == TRUE) {                       
    data$text_response[i] = NA
  }
  else if (n == 1) {
    data$text_response[i] = data$choice1[i]
  }
  else if (n == 2) {
    data$text_response[i] = data$choice2[i]
  }
  else if (n == 3) {
    data$text_response[i] = data$choice3[i]
  }
  else {
    data$text_response[i] = NA
  }
} 

# make column for modeling proportion correct
data$correct <- as.numeric((!is.na(data$text_response) & data$text_response == data$correct_answer) |
  (is.na(data$text_response) & data$old == 0))

# make column for calculating corrected recognition
#data$SDT[data$old == 1 & data$correct == 1] = 'hit'
#data$SDT[data$old == 0 & data$correct == 0] = 'falseAlarm'
#data$SDT[data$old == 1 & data$correct == 0] = 'miss'
#data$SDT[data$old == 0 & data$correct == 1] = 'correctRejection'

# make column for coding high vs. low confidence
#data$high_conf[data$confresp == 1 | data$confresp == 2] = 0
#data$high_conf[data$confresp == 3 | data$confresp == 4] = 1

```

# Tidy Questionnaires
```{r Tidy questionnaires, include=FALSE}
mfq <- select(all_surveys, starts_with('sub'), starts_with('mfq'))
disgust_scale <- select(all_surveys, starts_with('sub'), starts_with('disgust'))
secs <- select(all_surveys, starts_with('sub'), starts_with('secs'))
iri <- select(all_surveys, starts_with('sub'), starts_with('iri'))

# score MFQ
#part one
mfq[mfq == 'Not at all relevant' ] <- 0
mfq[mfq == 'Not very relevant' ] <- 1
mfq[mfq == 'Slightly relevant' ] <- 2
mfq[mfq == 'Somewhat relevant' ] <- 3
mfq[mfq == 'Very relevant' ] <- 4
mfq[mfq == 'Extremely relevant' ] <- 5
#part two
mfq[mfq == 'Strongly disagree' ] <- 0
mfq[mfq == 'Moderately disagree' ] <- 1
mfq[mfq == 'Slightly disagree' ] <- 2
mfq[mfq == 'Slightly agree' ] <- 3
mfq[mfq == 'Moderately agree' ] <- 4
mfq[mfq == 'Strongly agree' ] <- 5
# compute results
colnames(mfq) <- substr(colnames(mfq), 5, 7) 
names(mfq)[1] <- 'subID'
mfq <- mfq[-1,]
mfq[,2:33] <- as.numeric(unlist(mfq[,2:33]))
mfq <- mfq %>% mutate(careScore = rowSums(select(., c('1','7','12','17','23','28')), na.rm = TRUE),
                     fairnessScore = rowSums(select(., c('2','8','13','18','24','29')), na.rm = TRUE),
                     loyaltyScore = rowSums(select(., c('3','9','14','19','25','30')), na.rm = TRUE),
                     authorityScore = rowSums(select(., c('4','10','15','20','26','31')), na.rm = TRUE),
                     purityScore = rowSums(select(., c('5','11','16','21','27','32')), na.rm = TRUE))
hist(mfq$careScore) #slight negative skew, peak at 20-25 (count=12)
hist(mfq$fairnessScore) #considerable negative skew, peak at 20-25 (count=15)
hist(mfq$loyaltyScore) #more centrally distributed, peak at 10-15 (count=11) & 15-20 (count=12)
hist(mfq$authorityScore) #considerable negative skew, peak at 10-15 (count=12)
hist(mfq$purityScore) #most normally distributed of them all, peak at 15-20 (count=10)

# add to retrieval file
# mfq_ret <- subset(mfq, subID %in% ret_all$subID) %>% filter(subID != '20') %>% select(contains('Score'), contains('subID'))
# ret_all <- left_join(ret_all, mfq_ret, by = 'subID')


# score disgust_scale
#part one
disgust_scale[disgust_scale == 'Strongly disagree' ] <- 0
disgust_scale[disgust_scale == 'Mildly disagree' ] <- 1
disgust_scale[disgust_scale == 'Neither agree nor disagree' ] <- 2
disgust_scale[disgust_scale == 'Mildly agree' ] <- 3
disgust_scale[disgust_scale == 'Strongly agree' ] <- 4
#part two
disgust_scale[disgust_scale == 'Not disgusting at all' ] <- 0
disgust_scale[disgust_scale == 'Slightly disgusting' ] <- 1
disgust_scale[disgust_scale == 'Moderately disgusting' ] <- 2
disgust_scale[disgust_scale == 'Very disgusting' ] <- 3
disgust_scale[disgust_scale == 'Extremely disgusting' ] <- 4
# compute results
colnames(disgust_scale) <- as.character(c('subID', 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27)) 
disgust_scores <- select(disgust_scale, -'12', -'16') #get rid of catch questions
disgust_scores <- as.data.frame(disgust_scores[-1,]) 
disgust_scores[,2:25] <- as.numeric(unlist(disgust_scores[,2:25]))
reverse4 <- function(x) 4 - x
disgust_scores[,c('1','6','10')] <- reverse4(disgust_scores[,c('1','6','10')])
disgust_scores$score <- rowSums(disgust_scores[2:25])
hist(disgust_scores$score) #pretty normally distributed, peak at 50-60 (count=11)


# score iri
iri <- as.data.frame(sapply(iri, function(s) substr(s, 1, 2)), stringsAsFactors = FALSE)
colnames(iri) <- substr(colnames(iri), 5, 7) 
iri <- as.data.frame(sapply(iri, function(x) gsub("^\t* *\"* *| *\"* *\t*$", "", x)), stringsAsFactors = FALSE)
names(iri)[1] <- 'subID'
iri <- iri[-1,]
iri[iri == 'A' ] <- 0
iri[iri == 'B' ] <- 1
iri[iri == 'C' ] <- 2
iri[iri == 'D' ] <- 3
iri[iri == 'E' ] <- 4
iri[,2:29] <- as.numeric(unlist(iri[,2:29]))
reverseScoredIRI <- c('3', '4', '7', '12', '13', '14', '15', '18', '19')
iri[,reverseScoredIRI] <- reverse4(iri[,reverseScoredIRI])
#subscale coding
perspective_taking <- c('3','8','11','15','21','25','28')
fantasy <- c('1', '5', '7','12','16','23','26')
empathic_concern <- c('2','4','9','14','18','20','22')
personal_distress <- c('6','10','13','17', '19', '24','27')
#compute scores
iri <- iri %>% mutate(PerspectiveTakingScore = rowSums(select(., perspective_taking), na.rm = TRUE),
                     FantasyScore = rowSums(select(., fantasy), na.rm = TRUE),
                     EmpathicConcernScore = rowSums(select(., empathic_concern), na.rm = TRUE),
                     PersonalDistressScore = rowSums(select(., personal_distress), na.rm = TRUE))

# explore spread
# hist(iri$PerspectiveTakingScore)
# hist(iri$FantasyScore)
# hist(iri$EmpathicConcernScore)
# hist(iri$PersonalDistressScore)


# score secs - conservatism increases with score
colnames(secs) <- substr(colnames(secs), 6, 8) 
names(secs)[1] <- 'subID'
secs <- secs[-1,]
secs[,2:13] <- as.numeric(unlist(secs[,2:13]))
social <- c('1','3','4','7','8','11','12')
economic <- c('2', '5', '6', '9', '10')
reverse100 <- function(x) 100 - x
reverseScoredSECS <- c('1', '5')
secs[,reverseScoredSECS] <- reverse100(secs[,reverseScoredSECS])
secs <- secs %>% mutate(SocialConservatism = rowMeans(select(., social), na.rm = TRUE),
                       EconomicConservatism = rowMeans(select(., economic), na.rm = TRUE))
secs_ret <- subset(secs, subID %in% ret_all$subID) %>% filter(!is.nan(SocialConservatism)) %>% select(contains('subID'),contains('Conservatism'))

# explore spread
# hist(secs$SocialConservatism)
# count(secs, SocialConservatism >= 50)
# hist(secs$EconomicConservatism)
# count(secs, EconomicConservatism >= 50)

# tidy emorate
# emorate <- read.csv('C:/Users/imclab/Desktop/MFT re-analysis/data/qualtrics/emorate.csv', stringsAsFactors = FALSE)
# emorate[2:30, 2:721] <- as.data.frame(sapply(emorate[2:30, 2:721], function(s) substr(s, 1, 2)), stringsAsFactors = FALSE)
# names(emorate)[1] <- 'subID'
# emorate <- emorate[2:nrow(emorate),] %>% pivot_longer(2:ncol(emorate), names_to=c('vigfile', 'emotion'), names_pattern='([a-z]+\\d+)\\.*(.*)' , values_to='emoresp')
# emorate$emotion[emorate$emotion == ''] = 'angry'
# emorate$emotion[emorate$emotion == '1'] = 'sad'
# emorate$emotion[emorate$emotion == '2'] = 'disgusted'
# emorate$emotion[emorate$emotion == '3'] = 'afraid'
# emorate$emotion[emorate$emotion == '4'] = 'contemptuous'
# emorate$emotion[emorate$emotion == '5'] = 'amused'
# emorate$emoresp <- as.numeric(emorate$emoresp)
# emorate_ret <- subset(emorate, subID %in% ret_all$subID)
# 
# # add qualtrics information into main dataframe
# data <- left_join(data, mfq_ret, by='subID')
# data <- left_join(data, secs_ret, by='subID')
# count(data, SocialConservatism > 50)
# count(data, EconomicConservatism > 50)
# 
# data$socially_conservative[data$SocialConservatism > 50] = 1
# data$socially_conservative[data$SocialConservatism < 50] = 0
# data$fiscally_conservative[data$EconomicConservatism > 50] = 1
# data$fiscally_conservative[data$EconomicConservatism < 50] = 0

```

# Analyses: Linear Mixed Models
## Moral Judgments
```{r, fig.width=5, fig.height=5}

# look at spreads
hist(as.numeric(data$moral_decision))
hist(data$encoding_RT)
data$moral_decision <- as.integer(data$moral_decision)
data_old <- subset(data, old == '1' & moral_decision != 'NaN')
data_old$category <-  factor(data_old$category, levels = c('Care-Emo', 'Care-Phys', 'Fairness', 'Loyalty', 'Authority', 'Purity', 'Liberty', 'Social Norms'))
foundation_means <- data_old %>% as.integer(moral_decision) %>% group_by(category, subID) %>% summarise(mean = mean(moral_decision)) 

ggplot(data_old, aes(x=moral_decision, color=category, fill=category)) +
  geom_bar() + 
  facet_wrap(~category, nrow=2) + 
  ggtitle('Distribution of Moral Judgments') +
  xlab('1=not morally wrong, 4=extremely morally wrong')

ggplot(foundation_means, aes(x=category, y=mean, color=category, fill=category)) +
  geom_violin(scale='count', alpha=0.5) +
  stat_summary(fun.data = mean_se, fun.args = list(mult = 1.96), geom='pointrange', color='black', fatten=5) +
  ggtitle('Mean moral judgment per category')

ggplot(foundation_means, aes(x=category, y=mean, color=category, fill=category)) +
  stat_summary(fun.y = mean, geom='bar') +
  stat_summary(fun.data=mean_se, fun.args = list(mult=1.96), geom='errorbar', color='black', size=0.5, width=0.5) +
  coord_flip() +
  ggtitle('Visual comparison to Clifford et al. (2015)')

modelMoral <- brm(moral_decision ~ category + (1 + category | subID) + (1 | vigfile), 
                  family=cumulative(link="logit", threshold="flexible"), data=data_old, cores=4, file='mftMoralDecision')
summary(modelMoral)
conditional_effects(modelMoral)
conditional_effects(modelMoral, categorical=TRUE)

modelMoral <- mixor(moral_decision ~ category, data = data_old, id=subID, link='logit', KG = 1)
summary(modelMoral)

# test for meeting assumption of proportional odds
modelMoral.clm <- clm(moral_decision ~ category + subID, data = data_old)
nominal_test(modelMoral.clm)
scale_test(modelMoral.clm)

modelMoral %>% emmeans(~ category, type='response') %>% as.data.frame %>%
  ggplot(aes(x=category, y=prob)) +
  geom_pointrange(aes(ymax=asymp.LCL, ymin=asymp.UCL), alpha=1, fatten=5, color='black') +
  facet_wrap(~old, nrow=2) +
  geom_violin(aes(x=category, y=propCorrect, color=category, fill=category), data=data, alpha=0.2, scale='count') +
  ggtitle('Memory accuracy (hits & correct rejections)') + ylab('Estimated marginal means') + theme(legend.position = 'none')


modelMoral2 <- clmm(moral_decision ~ category + (1 | vigfile), data = data_old, Hess = TRUE)
summary(modelMoral2)


```




## Memory Accuracy: GLMM
```{r, fig.width=15, fig.height=8}

## some handy commands
# exp(fixef(modelOld1)): transforms model output from log likelihood to odds ratio
# anova(modelOld1, modelOld2): use for model comparisons [**don't look at the output of either model; use the results of this comparison to guide your result-seeking**]
# emmeans(modelNew, pairwise ~ category): gives you marginal means for each level of the fixed effect factor & pairwise comparisons among levels of the factor
# emmeans(modelNew, 'category', type='response'): gives you probabilities for each level of the fixed effect factor
# emmeans(modelOld1, pairwise ~ category, lmer.df = "satterthwaite"): gives you probabilities for each fixed effect and odds ratios + p-values for pairwise comparisons among levels of the fixed effect factor

data$high_conf[data$confresp == 1 | data$confresp == 2] = 0
data$high_conf[data$confresp == 3 | data$confresp == 4] = 1
data$confresp <- as.factor(as.numeric(data$confresp))
data$encoding_RT <- as.numeric(data$encoding_RT)
data$retrieval_RT <- as.numeric(data$retrieval_RT)
data$confRT <- as.numeric(data$confRT)
data_new <- subset(data, old == 0)
data_old$moral_decision <- as.factor(as.numeric(data_old$moral_decision))


# predicting accuracy using category
modelAccuracy <- glmer(correct ~ category + old + (1 + category | subID),
                 data=data, family=binomial(link = 'logit'), control=glmerControl(optCtrl=list(maxfun=50000)))
summary(modelAccuracy)
accuracyOdds <- exp(fixef(modelAccuracy))
accuracyContrasts <- emmeans(modelAccuracy, pairwise ~ category)

# plot
data <- data %>% group_by(subID, category, old) %>% mutate(propCorrect = mean(correct)) # so that violin plots can reflect participant response densities
modelAccuracy %>% emmeans(~ category * old, type='response') %>% as.data.frame %>%
  ggplot(aes(x=category, y=prob)) +
  geom_pointrange(aes(ymax=asymp.LCL, ymin=asymp.UCL), alpha=1, fatten=5, color='black') +
  facet_wrap(~old, nrow=2) +
  geom_violin(aes(x=category, y=propCorrect, color=category, fill=category), data=data, alpha=0.2, scale='count') +
  ggtitle('Memory accuracy (hits & correct rejections)') + ylab('Estimated marginal means') + theme(legend.position = 'none')

```


# Memory Confidence
```{r, fig.width=8, fig.height=4}


```

# Correlation between Accuracy and Moral Judgment
```{r, fig.width=8, fig.height=4}


```
